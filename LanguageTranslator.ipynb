{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af56c7f2-a536-4322-b215-07557635cb16",
   "metadata": {},
   "source": [
    "***********************************************************************************************************************************\n",
    "    Language Translator Model: English to Hindi.\n",
    "***********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4636a3a-536e-4162-9836-a5691da4828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2023.4.0)\n",
      "Requirement already satisfied: requests in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Requirement already satisfied: transformers in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: filelock in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: datasets in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Collecting pyarrow\n",
      "  Obtaining dependency information for pyarrow from https://files.pythonhosted.org/packages/f3/94/4e2a579bbac1adb19e63b054b300f6f7fa04f32f212ce86c18727bdda698/pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.16.6 (from pyarrow)\n",
      "  Obtaining dependency information for numpy>=1.16.6 from https://files.pythonhosted.org/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Installing collected packages: numpy, pyarrow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 16.0.0\n",
      "    Uninstalling pyarrow-16.0.0:\n",
      "      Successfully uninstalled pyarrow-16.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tensorflow-macos 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 pyarrow-16.1.0\n",
      "Requirement already satisfied: transformers in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: sentencepiece in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/db/Desktop/Anaconda/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "#Installing all the required packages.\n",
    "!pip install huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install datasets \n",
    "!pip install --upgrade --force-reinstall pyarrow\n",
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54a776d-e8d6-4a5d-90f3-ea39f6e22776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages.\n",
    "\n",
    "import datasets         \n",
    "import torch           \n",
    "import transformers     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebf5bcf-e01f-4e56-bd5d-dd574f09c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/db/.cache/huggingface/datasets/Ketan3101___parquet/Ketan3101--English-Hindi-Translation-d3447c8bcbbfe1e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c30ebe55e0a427ab592db82a952d13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: {'english': 'Police have released a sketch of one of the militants believed to be in the city.', 'hindi': 'पुलिस ने आतंकवादियों में से एक का रेखाचित्र जारी किया है जिसके बारे में माना जा रहा है कि वह शहर में है।'}\n",
      "Hindi: {'english': 'Police indicated that he had taken his own life.', 'hindi': 'पुलिस ने संकेत दिया कि उसने अपनी जान ले ली है।'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#Loading the dataset from Hugging Face.\n",
    "dataset = load_dataset('Ketan3101/English-Hindi-Translation')\n",
    "\n",
    "#Accessing the 'train' split.\n",
    "train_data = dataset['train']\n",
    "\n",
    "#Initializing the variables to collect translations.\n",
    "english_translation = None\n",
    "hindi_translation = None\n",
    "\n",
    "#Iterating through the dataset and extracting the translations.\n",
    "for idx, example in enumerate(train_data):\n",
    "    if example == 'english':\n",
    "        #Skipping the 'english' marker and continue to the next item.\n",
    "        continue\n",
    "    elif example == 'hindi':\n",
    "        #If encountering 'hindi' marker, printing the collected translations.\n",
    "        if english_translation and hindi_translation:\n",
    "            print(f\"English: {english_translation}\")\n",
    "            print(f\"Hindi: {hindi_translation}\")\n",
    "            print(\"-\" * 20)\n",
    "            english_translation = None\n",
    "            hindi_translation = None\n",
    "    else:\n",
    "        #Collectting the English and Hindi translations.\n",
    "        if english_translation is None:\n",
    "            english_translation = example\n",
    "        elif hindi_translation is None:\n",
    "            hindi_translation = example\n",
    "\n",
    "#Printing the last collected translations (if any).\n",
    "if english_translation and hindi_translation:\n",
    "    print(f\"English: {english_translation}\")\n",
    "    print(f\"Hindi: {hindi_translation}\")\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5efeec53-cc09-496a-988a-76917cc7314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/db/.cache/huggingface/datasets/Ketan3101___parquet/Ketan3101--English-Hindi-Translation-d3447c8bcbbfe1e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0607268398444ed8d8cbaf6d269c059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 279014\n",
      "Validation examples: 34877\n",
      "Test examples: 34877\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Loading the dataset from Hugging Face.\n",
    "dataset = load_dataset('Ketan3101/English-Hindi-Translation')\n",
    "\n",
    "#Accessing the train dataset.\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "#Converting to pandas DataFrame.\n",
    "train_df = train_dataset.to_pandas()\n",
    "\n",
    "#Splitting the DataFrame into training 80% and remaining data 20%.\n",
    "train_data, remaining_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Splitting the remaining data into validation 50% and test 50%.\n",
    "val_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "\n",
    "#Printing the sizes of each split.\n",
    "print(f\"Training examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(val_data)}\")\n",
    "print(f\"Test examples: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "505bcf6b-9726-4030-9700-f9265b17bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter English text:  I love my country\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi translation: मैं अपने देश से प्यार\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "\n",
    "def translate_english_to_hindi(input_text):\n",
    "    #Model name for English to Hindi translation.\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "\n",
    "    #Loading tokenizer and model.\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    #Tokenizing the input text.\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    #Generating the translation with maximum new tokens limit.\n",
    "    translated_ids = model.generate(**inputs, max_length=128)\n",
    "\n",
    "    #Decoding the translated sequence into text.\n",
    "    translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "#Taking input from the user as English Text.\n",
    "english_input = input(\"Enter English text: \")\n",
    "\n",
    "#Calling the translation function with the user's input.\n",
    "hindi_output = translate_english_to_hindi(english_input)\n",
    "\n",
    "#Delivering the Hindi translation.\n",
    "print(\"Hindi translation:\", hindi_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3bd6711-68c3-46c9-a1ef-432fac40fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on Test Set Translations: 2.3498596787621384e+24\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "#Defining a function to calculate the Perplexity of the model.\n",
    "def calculate_perplexity(model, test_data):\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for example in test_data:\n",
    "        english_ids = torch.tensor(example['English']).unsqueeze(0).to(model.device)\n",
    "        hindi_ids = torch.tensor(example['Hindi']).unsqueeze(0).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=english_ids, labels=hindi_ids)[1]\n",
    "            loss_fn = CrossEntropyLoss(reduction='sum')\n",
    "            batch_loss = loss_fn(logits.view(-1, logits.size(-1)), hindi_ids.view(-1))\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "        total_tokens += hindi_ids.size(1)\n",
    "\n",
    "    avg_loss = total_loss / len(test_data)\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss)) \n",
    "\n",
    "    return perplexity.item()\n",
    "\n",
    "#Sample data collection from the test split.\n",
    "test_data = [\n",
    "    {'English': [1, 123, 456, 789], 'Hindi': [1, 321, 654, 987]},  \n",
    "    {'English': [1, 234, 567, 890], 'Hindi': [1, 432, 765, 98]}\n",
    "]\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-hi'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "#Calculating perplexity on the test set\n",
    "test_perplexity = calculate_perplexity(model, test_data)\n",
    "print(f\"Perplexity on Test Set Translations: {test_perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21374ccf-19b3-4fee-9e67-9ac30a116e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
