{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d684996f-a2c3-4ab2-a0ab-5d69ccec29f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9245182959165635\n",
      "Testing Accuracy: 0.9245182959165635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loadingthe twenty user groups dataset\n",
    "twenty_users = fetch_20newsgroups()\n",
    "\n",
    "# Creating a CountVectorizer with default parameters\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Transforming the training data using CountVectorizer\n",
    "X_train_counts = count_vectorizer.fit_transform(twenty_users.data)\n",
    "\n",
    "# Getting the total number of documents\n",
    "total_documents = X_train_counts.shape[0]\n",
    "\n",
    "# Calculating the document frequency of each word\n",
    "word_freq = np.asarray(X_train_counts.sum(axis=0)).squeeze()\n",
    "document_freq = word_freq / total_documents\n",
    "\n",
    "# Finding words appearing in less than 2.5% or more than 97.5% of documents\n",
    "stopwords_25 = [word for word, df in zip(count_vectorizer.get_feature_names_out(), document_freq) if df < 0.025]\n",
    "stopwords_975 = [word for word, df in zip(count_vectorizer.get_feature_names_out(), document_freq) if df > 0.975]\n",
    "\n",
    "# Adding the stopwords to the CountVectorizer\n",
    "count_vectorizer.stop_words_.update(stopwords_25)\n",
    "count_vectorizer.stop_words_.update(stopwords_975)\n",
    "\n",
    "# Transforming the testing data using CountVectorizer\n",
    "X_test_counts = count_vectorizer.transform(twenty_users.data)\n",
    "\n",
    "# Training a Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_counts, twenty_users.target)\n",
    "\n",
    "# Prediction on the training and testing data\n",
    "train_predictions = classifier.predict(X_train_counts)\n",
    "test_predictions = classifier.predict(X_test_counts)\n",
    "\n",
    "# Calculating accuracy on the training and testing data\n",
    "train_accuracy = accuracy_score(twenty_users.target, train_predictions)\n",
    "test_accuracy = accuracy_score(twenty_users.target, test_predictions)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3340e923-af13-4522-969d-c15639a4ac74",
   "metadata": {},
   "source": [
    "    What does this do to the accuracy of the classifier on the training set? On the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8ed11-3d59-46dd-be0c-7002d56ac02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
