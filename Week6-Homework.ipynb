{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6634b7-dab2-4380-9be3-e0b142782302",
   "metadata": {},
   "source": [
    "    Week6-Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887d4348-95f5-4b5a-a1b1-0b91b4e31497",
   "metadata": {},
   "source": [
    "    Q11. Learn about the affix tagger (type help(nltk.AffixTagger)). Train an affix tagger and run it on some new text. Experiment with different settings for the affix length and the minimum word length. Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dceb40-0eeb-4281-8a3e-3340f5726c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affix length: 2, Min word length: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/d10tw0x10ngd3fsg70yr4v9m0000gn/T/ipykernel_37555/4138137748.py:18: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  return tagger.evaluate(test_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2050195096102895\n",
      "Affix length: 2, Min word length: 3\n",
      "Accuracy: 0.14697239751433114\n",
      "Affix length: 2, Min word length: 4\n",
      "Accuracy: 0.11012091141191772\n",
      "Affix length: 3, Min word length: 2\n",
      "Accuracy: 0.17780239895948746\n",
      "Affix length: 3, Min word length: 3\n",
      "Accuracy: 0.1267402090659473\n",
      "Affix length: 3, Min word length: 4\n",
      "Accuracy: 0.09470591068933956\n",
      "Affix length: 4, Min word length: 2\n",
      "Accuracy: 0.13290620935497857\n",
      "Affix length: 4, Min word length: 3\n",
      "Accuracy: 0.09865600462450022\n",
      "Affix length: 4, Min word length: 4\n",
      "Accuracy: 0.061660002890312635\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "#Loading the Brown corpus\n",
    "corpus = brown.tagged_sents(categories='news')\n",
    "\n",
    "#Splitting the data into training and testing sets\n",
    "train_data = corpus[:int(0.8 * len(corpus))]\n",
    "test_data = corpus[int(0.8 * len(corpus)):]\n",
    "\n",
    "#Training an AffixTagger with different settings\n",
    "def train_affix_tagger(affix_length, min_word_length):\n",
    "    affix_tagger = nltk.AffixTagger(train_data, affix_length=affix_length, min_stem_length=min_word_length)\n",
    "    return affix_tagger\n",
    "\n",
    "#Function to evaluate the tagger\n",
    "def evaluate_tagger(tagger, test_data):\n",
    "    return tagger.evaluate(test_data)\n",
    "\n",
    "#Trying different settings\n",
    "affix_lengths = [2, 3, 4]  # Try different lengths for prefixes and suffixes\n",
    "min_word_lengths = [2, 3, 4]  # Try different minimum word lengths\n",
    "\n",
    "for affix_length in affix_lengths:\n",
    "    for min_word_length in min_word_lengths:\n",
    "        print(f\"Affix length: {affix_length}, Min word length: {min_word_length}\")\n",
    "        affix_tagger = train_affix_tagger(affix_length, min_word_length)\n",
    "        accuracy = evaluate_tagger(affix_tagger, test_data)\n",
    "        print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88926f5-d40d-4f72-9746-4cfc78fd091a",
   "metadata": {},
   "source": [
    "Here are some observations based on the results:\n",
    "\n",
    "Affix Length:\n",
    "Generally, shorter affix lengths (2 or 3) tend to have higher accuracies compared to longer ones (4). This suggests that shorter affixes might capture more meaningful patterns in the data.\n",
    "The accuracy decreases as the affix length increases, which might indicate that longer affixes result in more sparse and less reliable patterns.\n",
    "\n",
    "Minimum Word Length:\n",
    "Similar to affix length, shorter minimum word lengths (2 or 3) tend to yield higher accuracies compared to longer ones (4).\n",
    "However, the difference in accuracy between different minimum word lengths is less pronounced compared to affix length. This could suggest that the impact of minimum word length on accuracy is not as significant as affix length.\n",
    "\n",
    "Overall:\n",
    "The highest accuracy achieved is around 20.5%, which indicates that the AffixTagger alone might not be sufficient for achieving high accuracy in part-of-speech tagging tasks.\n",
    "It's important to note that these results are specific to the Brown corpus and may vary with different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31ee13-92ba-47f5-a027-41185482c586",
   "metadata": {},
   "source": [
    "    Q14. Use sorted() and set() to get a sorted list of tags used in the Brown Corpus, removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296bb498-6e3e-462f-a258-229c540eb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/db/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "#Getting the tags from the Brown Corpus\n",
    "tags = brown.tagged_words(tagset='universal')\n",
    "\n",
    "#Extracting unique tags and sort them\n",
    "unique_tags = sorted(set(tag for word, tag in tags))\n",
    "\n",
    "print(unique_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc973163-98f8-440b-9826-9ef847b80edd",
   "metadata": {},
   "source": [
    "    Q15. Write programs to process the Brown Corpus and find answers to the following questions:\n",
    "\n",
    "    a. Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b80b4e-a65a-42cf-bf46-14f15b00434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/db/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns more common in their plural form than singular form:\n",
      "personnel\n",
      "criticisms\n",
      "employes\n",
      "means\n",
      "reservoirs\n",
      "kept\n",
      "police\n",
      "drafts\n",
      "we'll\n",
      "years'\n",
      "parks\n",
      "ours\n",
      "beliefs\n",
      "clubs\n",
      "blows\n",
      "breaks\n",
      "crowds\n",
      "feels\n",
      "boys\n",
      "reflexes\n",
      "guys\n",
      "works\n",
      "strokes\n",
      "triumphs\n",
      "People\n",
      "bombs\n",
      "stairs\n",
      "pardon\n",
      "east\n",
      "troops\n",
      "data\n",
      "employ\n",
      "grandchildren\n",
      "eggs\n",
      "ribs\n",
      "months'\n",
      "m.p.h.\n",
      "headquarters\n",
      "roles\n",
      "robes\n",
      "yarn\n",
      "lamps\n",
      "legs\n",
      "relationships\n",
      "dreams\n",
      "toys\n",
      "films\n",
      "sofas\n",
      "armchairs\n",
      "tours\n",
      "downstairs\n",
      "propaganda\n",
      "mechanisms\n",
      "brethren\n",
      "women's\n",
      "bags\n",
      "drops\n",
      "teeth\n",
      "bats\n",
      "tribes\n",
      "guns\n",
      "shadows\n",
      "lags\n",
      "seams\n",
      "valleys\n",
      "magic\n",
      "hooks\n",
      "isn't\n",
      "stems\n",
      "hopefuls\n",
      "hysteria\n",
      "reads\n",
      "throats\n",
      "baths\n",
      "won't\n",
      "they'd\n",
      "thru\n",
      "cafes\n",
      "thugs\n",
      "sixty\n",
      "rags\n",
      "clouds\n",
      "cannot\n",
      "nightclubs\n",
      "orchestras\n",
      "proud\n",
      "formulas\n",
      "compete\n",
      "orchestra\n",
      "cooks\n",
      "discs\n",
      "left\n",
      "didn't\n",
      "frank\n",
      "souls\n",
      "epigrams\n",
      "limbs\n",
      "sonatas\n",
      "wet\n",
      "chantey\n",
      "contours\n",
      "suburbs\n",
      "glad\n",
      "lobes\n",
      "salesmen\n",
      "keys\n",
      "lawns\n",
      "maze\n",
      "marinas\n",
      "lbs.\n",
      "milligrams\n",
      "menu\n",
      "evil\n",
      "sphere\n",
      "mankind\n",
      "maps\n",
      "peas\n",
      "thousand\n",
      "bonzes\n",
      "thou\n",
      "yours\n",
      "mobs\n",
      "gonna\n",
      "doesn't\n",
      "You'll\n",
      "lengths\n",
      "thighs\n",
      "mulch\n",
      "galleys\n",
      "diagrams\n",
      "drill\n",
      "puzzle\n",
      "kid\n",
      "herbs\n",
      "visit\n",
      "cowboys\n",
      "cattle\n",
      "cups\n",
      "pearls\n",
      "buns\n",
      "cup\n",
      "lid\n",
      "transom\n",
      "sizes\n",
      "you'll\n",
      "beams\n",
      "alas\n",
      "know\n",
      "photos\n",
      "shrubs\n",
      "geese\n",
      "palms\n",
      "bacteria\n",
      "specimen\n",
      "cm.\n",
      "phenomena\n",
      "scours\n",
      "milligram\n",
      "lambs\n",
      "today's\n",
      "couldn't\n",
      "cafeteria\n",
      "rigs\n",
      "lb.\n",
      "bulky\n",
      "manhours\n",
      "crags\n",
      "cheese\n",
      "felt\n",
      "barracks\n",
      "rugs\n",
      "hymen\n",
      "helps\n",
      "frauds\n",
      "jaws\n",
      "thumbs\n",
      "$750\n",
      "speaks\n",
      "memoirs\n",
      "fifty\n",
      "pegs\n",
      "ten\n",
      "cops\n",
      "strode\n",
      "wryly\n",
      "cloth\n",
      "hundred\n",
      "upstairs\n",
      "tung\n",
      "soaps\n",
      "kernel\n",
      "man's\n",
      "rhinoceros\n",
      "friezes\n",
      "columns\n",
      "ruin\n",
      "barren\n",
      "courtesy\n",
      "poems\n",
      "toughs\n",
      "antagonisms\n",
      "akin\n",
      "marijuana\n",
      "verbenas\n",
      "spurs\n",
      "straws\n",
      "devil\n",
      "stimuli\n",
      "bogeys\n",
      "occurs\n",
      "nostalgia\n",
      "shaky\n",
      "faith\n",
      "coups\n",
      "crowd\n",
      "hello\n",
      "stubs\n",
      "wasn't\n",
      "twelve\n",
      "father's\n",
      "chosen\n",
      "characteristic\n",
      "motifs\n",
      "monei\n",
      "nott\n",
      "blind\n",
      "dystopias\n",
      "plugs\n",
      "ghettos\n",
      "proxy\n",
      "ashamed\n",
      "spectra\n",
      "certiorari\n",
      "kc.\n",
      "fiber\n",
      "cm\n",
      "lunar\n",
      "mm\n",
      "hr.\n",
      "solids\n",
      "photographs\n",
      "alkali\n",
      "mm.\n",
      "ml\n",
      "nectar\n",
      "andrenas\n",
      "hairs\n",
      "prairie\n",
      "septa\n",
      "mg.\n",
      "cc.\n",
      "smooth\n",
      "swollen\n",
      "nuclei\n",
      "devoid\n",
      "nucleoli\n",
      "mg\n",
      "green\n",
      "neocortex\n",
      "bull's-eyes\n",
      "mice\n",
      "dice\n",
      "**zg\n",
      "mother's\n",
      "subsystems\n",
      "texts\n",
      "what's\n",
      "al\n",
      "grasp\n",
      "verbs\n",
      "formulae\n",
      "twentieth\n",
      "vague\n",
      "postwar\n",
      "ask\n",
      "Men\n",
      "whereabouts\n",
      "o'clock\n",
      "frescos\n",
      "channel\n",
      "lb\n",
      "mg/l\n",
      "complexes\n",
      "alloys\n",
      "foams\n",
      "glycol\n",
      "suds\n",
      "joys\n",
      "flour\n",
      "mothers'\n",
      "cheeks\n",
      "draws\n",
      "cleaner\n",
      "damp\n",
      "grey\n",
      "dirty\n",
      "purple\n",
      "saddlebags\n",
      "she'd\n",
      "you're\n",
      "colonel\n",
      "buckle\n",
      "maid\n",
      "heroic\n",
      "drunk\n",
      "mad\n",
      "kitchen\n",
      "boroughs\n",
      "don't\n",
      "you've\n",
      "hat\n",
      "horn\n",
      "flannel\n",
      "ye\n",
      "taut\n",
      "clientele\n",
      "shut\n",
      "he'd\n",
      "you'd\n",
      "screams\n",
      "calm\n",
      "goin\n",
      "clad\n",
      "comin'\n",
      "he'll\n",
      "it's\n",
      "feel\n",
      "nothin'\n",
      "down\n",
      "muddy\n",
      "copra\n",
      "outlaws\n",
      "'em\n",
      "ya\n",
      "ain't\n",
      "dregs\n",
      "buds\n",
      "wouldn't\n",
      "father\n",
      "we're\n",
      "cognac\n",
      "forty\n",
      "tombs\n",
      "flu\n",
      "pink\n",
      "salad\n",
      "theirs\n",
      "hurt\n",
      "paws\n",
      "company's\n",
      "broken\n",
      "gags\n",
      "concertos\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load the Brown Corpus and tokenize words\n",
    "words = brown.words()\n",
    "tagged_words = nltk.pos_tag(words)\n",
    "\n",
    "# Initialize set to store singular nouns\n",
    "singular_nouns = set()\n",
    "\n",
    "# Iterate through tagged words to identify singular nouns\n",
    "for word, tag in tagged_words:\n",
    "    if tag == 'NN':  # Singular noun\n",
    "        singular_nouns.add(word)\n",
    "\n",
    "# Initialize dictionary to store counts of plural nouns\n",
    "plural_counts = {}\n",
    "\n",
    "# Iterate through tagged words again to count plural nouns\n",
    "for word, tag in tagged_words:\n",
    "    if tag == 'NNS':  # Plural noun\n",
    "        if word in singular_nouns:  # Check if the singular form exists\n",
    "            plural_counts[word] = plural_counts.get(word, 0) + 1\n",
    "\n",
    "# Identify nouns that are more common in their plural form than singular form\n",
    "more_common_plural = [word for word, count in plural_counts.items() if count > 0]\n",
    "\n",
    "# Print the list of nouns\n",
    "print(\"Nouns more common in their plural form than singular form:\")\n",
    "for word in more_common_plural:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e7fb2-2b52-489d-aaba-05738e2fa998",
   "metadata": {},
   "source": [
    "    b. Which word has the greatest number of distinct tags? What are they, and what do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea26f09-6da1-4b37-9170-c9049cfbbc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/db/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/db/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with the greatest number of distinct tags is 'that'\n",
      "Distinct tags and their meanings:\n",
      "No matching tags found.\n",
      "WPO-NC: None\n",
      "No matching tags found.\n",
      "CS: None\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "DT: None\n",
      "No matching tags found.\n",
      "CS-HL: None\n",
      "No matching tags found.\n",
      "DT-NC: None\n",
      "No matching tags found.\n",
      "CS-NC: None\n",
      "No matching tags found.\n",
      "NIL: None\n",
      "No matching tags found.\n",
      "WPS-NC: None\n",
      "No matching tags found.\n",
      "WPO: None\n",
      "No matching tags found.\n",
      "QL: None\n",
      "No matching tags found.\n",
      "WPS: None\n",
      "No matching tags found.\n",
      "WPS-HL: None\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "# Load the Brown Corpus and tokenize words\n",
    "tagged_words = nltk.corpus.brown.tagged_words()\n",
    "\n",
    "# Initialize a dictionary to store distinct tags for each word\n",
    "word_tags = {}\n",
    "\n",
    "# Iterate through tagged words to count distinct tags for each word\n",
    "for word, tag in tagged_words:\n",
    "    if word not in word_tags:\n",
    "        word_tags[word] = set()  # Initialize set for new word\n",
    "    word_tags[word].add(tag)  # Add tag to the set for the word\n",
    "\n",
    "# Find the word with the greatest number of distinct tags\n",
    "max_word = max(word_tags, key=lambda word: len(word_tags[word]))\n",
    "max_tags = word_tags[max_word]\n",
    "\n",
    "# Print the word and its distinct tags\n",
    "print(f\"The word with the greatest number of distinct tags is '{max_word}'\")\n",
    "print(\"Distinct tags and their meanings:\")\n",
    "for tag in max_tags:\n",
    "    print(f\"{tag}: {nltk.help.upenn_tagset(tag)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fde96a-f2a1-4797-ab10-71e08e5b6164",
   "metadata": {},
   "source": [
    "    c.List tags in order of decreasing frequency. What do the 20 most frequent tags represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2742ed3f-e426-4362-a979-2faa5112d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most frequent tags and their frequencies:\n",
      "NN: 152470\n",
      "IN: 120557\n",
      "AT: 97959\n",
      "JJ: 64028\n",
      ".: 60638\n",
      ",: 58156\n",
      "NNS: 55110\n",
      "CC: 37718\n",
      "RB: 36464\n",
      "NP: 34476\n",
      "VB: 33693\n",
      "VBN: 29186\n",
      "VBD: 26167\n",
      "CS: 22143\n",
      "PPS: 18253\n",
      "VBG: 17893\n",
      "PP$: 16872\n",
      "TO: 14918\n",
      "PPSS: 13802\n",
      "CD: 13510\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "\n",
    "# Load the Brown Corpus and tokenize words\n",
    "tagged_words = nltk.corpus.brown.tagged_words()\n",
    "\n",
    "# Count the occurrences of each tag\n",
    "tag_counts = Counter(tag for word, tag in tagged_words)\n",
    "\n",
    "# Sort the tags by frequency in descending order\n",
    "sorted_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the 20 most frequent tags\n",
    "print(\"The 20 most frequent tags and their frequencies:\")\n",
    "for tag, count in sorted_tags[:20]:\n",
    "    print(f\"{tag}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eae82f-05a9-4c6a-917a-00242f8b79a3",
   "metadata": {},
   "source": [
    "    d. Which tags are nouns most commonly found after? What do these tags represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fea3fdf-3a3e-48e8-bf34-8d2ae4dda4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common tags that follow each type of noun:\n",
      "NN-TL: NN-TL (1914 occurrences)\n",
      "NN: IN (42256 occurrences)\n",
      "NNS: IN (14505 occurrences)\n",
      "NN-HL: IN-HL (240 occurrences)\n",
      "NN$-TL: NN (136 occurrences)\n",
      "NN$: NN (887 occurrences)\n",
      "NNS-HL: IN-HL (110 occurrences)\n",
      "NNS-TL: , (381 occurrences)\n",
      "NNS$: NN (116 occurrences)\n",
      "NNS$-TL: NN-TL (38 occurrences)\n",
      "NN-TL-HL: NN-TL-HL (24 occurrences)\n",
      "NNS-TL-HL: :-HL (6 occurrences)\n",
      "NN$-HL: NN-HL (19 occurrences)\n",
      "NNS$-HL: NNS-HL (3 occurrences)\n",
      "NN-NC: '' (35 occurrences)\n",
      "NN+HVZ: VBN (3 occurrences)\n",
      "NN+BEZ: VBN (6 occurrences)\n",
      "NNS-NC: BER-NC (3 occurrences)\n",
      "NN+MD: VB (2 occurrences)\n",
      "NNS-TL-NC: '' (2 occurrences)\n",
      "NN-TL-NC: '' (3 occurrences)\n",
      "NNS$-TL-HL: NN-TL-HL (1 occurrences)\n",
      "NNS$-NC: JJ (1 occurrences)\n",
      "NN+NN-NC: , (1 occurrences)\n",
      "NN+IN: JJ (1 occurrences)\n",
      "NN+HVD-TL: BEN (1 occurrences)\n",
      "NN+BEZ-TL: VBN (1 occurrences)\n",
      "NN+HVZ-TL: VBN (1 occurrences)\n",
      "NNS+MD: ABN (1 occurrences)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "\n",
    "#Loading the Brown Corpus and tokenize words\n",
    "tagged_words = nltk.corpus.brown.tagged_words()\n",
    "\n",
    "#Initializing a dictionary to store tags that follow nouns and their frequencies\n",
    "tags_after_nouns = {}\n",
    "\n",
    "#Iteratimng through tagged words to identify tags that follow nouns and count their occurrences\n",
    "for i in range(len(tagged_words) - 1):\n",
    "    current_word, current_tag = tagged_words[i]\n",
    "    next_word, next_tag = tagged_words[i + 1]\n",
    "    if current_tag.startswith('NN'):  # Check if the current word is a noun\n",
    "        if current_tag not in tags_after_nouns:\n",
    "            tags_after_nouns[current_tag] = Counter()  # Initialize counter for the tag\n",
    "        tags_after_nouns[current_tag][next_tag] += 1  # Increment the count for the following tag\n",
    "\n",
    "#Finding the most common tags that follow each type of noun\n",
    "most_common_tags_after_nouns = {noun_tag: tag_counter.most_common(1) for noun_tag, tag_counter in tags_after_nouns.items()}\n",
    "\n",
    "#Printing the most common tags that follow each type of noun\n",
    "print(\"Most common tags that follow each type of noun:\")\n",
    "for noun_tag, common_tags in most_common_tags_after_nouns.items():\n",
    "    print(f\"{noun_tag}: {common_tags[0][0]} ({common_tags[0][1]} occurrences)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b074f4b-5452-45b0-ac45-c12db9061a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
